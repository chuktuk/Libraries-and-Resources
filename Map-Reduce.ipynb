{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basics\n",
    "    - programming model for *very* large datasets\n",
    "    - parallel and distributed algorithms\n",
    "    - cluster framework\n",
    "    - also a way of thinking\n",
    "- Background\n",
    "    - originally developed by Google\n",
    "    - Apache Hadoop is open source implementation in Java\n",
    "    - MrJob is the python interface\n",
    "        - will not run in IPython notebooks, must run in a script\n",
    "- Process (all about key/value pairs)\n",
    "    - mapping\n",
    "        - data input is in single key/value pairs\n",
    "        - data is then shuffled, sorted, and aggregated according to the keys\n",
    "            - data of the same key is aggregated to that key\n",
    "    - reducing\n",
    "        - the data dictionaries associated with the keys is reduced using a specified algorithm (sum, mean, etc.)\n",
    "- MrJob `from mrjob.job import MRJob`\n",
    "    - program the mapper and the reducer\n",
    "    - create a class that inherits from MRJob\n",
    "        - define a mapper function and a reducer function\n",
    "        - call the function\n",
    "        - see famous word count example below\n",
    "```Python\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class mrWordCount(MRJob):\n",
    "    \n",
    "    # return each word (key) with a one (value)\n",
    "    def mapper(self,key,line):\n",
    "        for word in line.split(' '):\n",
    "            yield word.lower(),1\n",
    "    \n",
    "    # aggregate the occurrences for each word by summing the ones\n",
    "    def reducer(self,word,occurrences):\n",
    "        yield word, sum(occurrences)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mrWordCount.run()\n",
    "```\n",
    "- Running the script\n",
    "`python pythonfile.py < inputfile.txt > outfile.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anagram finder\n",
    "```python\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRAnagram(MRJob):\n",
    "\"\"\"Must pass file with cleaned text (all lowercase letters, no special chars) and 1 word per line\"\"\"\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        # convert letters to a list, sort, then convert back to string\n",
    "        letters = list(line)\n",
    "        letters.sort()\n",
    "        \n",
    "        # key is the sorted word, value is the regular word\n",
    "        yield letters, line\n",
    "        \n",
    "    def reducer(self, _, words):\n",
    "        # get the list of words containing these letters\n",
    "        anagrams = [w for w in words]\n",
    "        \n",
    "        # only yield answer for which there are two or more words with those letters\n",
    "        if len(anagrams) > 1:\n",
    "            yield len(anagrams), anagrams\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    MRAnagram.run()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
