{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# import create_engine from sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# import web scraping functions\n",
    "from urllib.request import urlretrieve, urlopen, Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Info and Commands\n",
    "#### Basic Commands\n",
    "- These commands assume a dataframe name of `df`\n",
    "- Methods\n",
    "    - Print the 'head' or first 5 rows\n",
    "        - `print(df.head())` use the '.head()' method of a dataframe\n",
    "        - works without the `print()` call\n",
    "        - supply an optional `int` as an arg to display that number of rows\n",
    "    - Print the 'tail' or last 5 rows\n",
    "        - `print(df.tail())`\n",
    "        - works without the `print()` call\n",
    "        - accepts optional int arg just as .head() does\n",
    "    - Access the 'keys' of a dataframe\n",
    "        - `df.keys()`\n",
    "    - Access general info including number of non-null values and datatypes\n",
    "        - `df.info()`\n",
    "- Attributes\n",
    "    - Print the 'columns' of a dataframe\n",
    "        - `df.columns`\n",
    "    - Print the 'indexes' of a dataframe\n",
    "        - `df.index`\n",
    "- Combining indexing with other methods\n",
    "    - you have a dataframe that each key is associated with a dataframe (a dataframe of dataframes)\n",
    "    - `print(df['key1'].head())` will print the head of the dataframe associate with 'key1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats\n",
    "- `df.describe`\n",
    "    - provides the following summary stats for each column\n",
    "        - count, mean, std, min, 25% (1st quartile), 50% (median), 75% (3rd quartile), max\n",
    "    - null entries are ignored for all stats\n",
    "        - counts only include non null values\n",
    "    - can supply an index `df['col'].describe()` to restrict to specific columns\n",
    "        - provides different results for categories\n",
    "            - unique (num distinct entries), top (most frequent entry), freq (occurrences of top)\n",
    "- `df['col'].unique()`\n",
    "    - returns a list of unique values for the column\n",
    "    - best used with categorical data\n",
    "- `df.quantile(q)`\n",
    "    - where q is a fractional number\n",
    "        - can supply a list of such numbers, output is provided in labeled rows\n",
    "        - interquartile range (IQR)\n",
    "            - `df.quantile([0.25, 0.75])`\n",
    "    - provides the value at the specified quantile (0.25, 0.5, 0.75, etc.)\n",
    "    - command above produces output for all numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Converting DataFrames\n",
    "\n",
    "#### Creating a Dataframe\n",
    "- From a python dictionary as `dict`\n",
    "    - `df = pd.DataFrame(dict)`\n",
    "        - keys become column names, values remain values\n",
    "        - row labels are auto generated, 0 indexed\n",
    "        - values are broadcast to fill entire column if unequal length\n",
    "            - `df = pd.DataFrame({'Names': list_of_names, 'Sex': 'M'})`\n",
    "            - every row has a value of 'M' for 'Sex' column\n",
    "- From python lists\n",
    "    - generate a list of `column_labels`\n",
    "    - generate a list of `values`, which is a list of lists\n",
    "        - the inner lists hold all the values\n",
    "        - the outer list holds variables for the inner lists\n",
    "            - must be in the correct order for the labels\n",
    "            - See example below for code\n",
    "    - use `dict(list(zip(column_labels, values)))`\n",
    "        - can break this up into two or more steps for readability\n",
    "    - use `pd.DataFrame` on the dict created above\n",
    "- From a CSV file\n",
    "    - `df = pd.read_csv('path/to/file.csv')`\n",
    "        - can set `index_col=0` if you don't want pandas to auto generate row numbers in an unnamed column\n",
    "        - set `header=None` if there are no column headers\n",
    "        - see 'Working with Flat Files' section below\n",
    "    - Formatting CSV for input\n",
    "        - good practice to use unnamed col with row keys\n",
    "        - can let pandas generate this, or set up CSV file with no col name and row keys in first col\n",
    "- Adding a column to a dataframe\n",
    "    - `df['new_column'] = values`\n",
    "        - can use calculated values, values from another column, or assign a single value for each row\n",
    "\n",
    "#### Changing Index (row labels)\n",
    "- Create a list as `list_of_indexes` with length equal to the number of rows\n",
    "    - `df.index = list_of_indexes`\n",
    "- Convert to time series index\n",
    "    - `df.index = df[time_column]`\n",
    "    - `df = df.sort_index` to then sort by that index\n",
    "    - Another way, if you have a 'Date' column as a string in your df\n",
    "        - `df.Date = pd.to_datetime(df['Date'])`\n",
    "        - `df.set_index('Date', inplace=True)`\n",
    "            - can modify the index this way without having to reassign it to the df\n",
    "    - - **Parse the date and set as index during import**\n",
    "        - set `index_col='date'` and `parse_dates=True` or just set 'index_col' to your date col if not parsing\n",
    "- Rename your index column\n",
    "    - `df.index.name = 'index_name'`\n",
    "- Reindexing\n",
    "    - Assigns a new index to a dataframe\n",
    "        - `df.reindex(list[, method=])`\n",
    "            - reindexes the dataframe using the supplied list\n",
    "        - tries to match based on the old dataframe\n",
    "        - any missing values are filled with NaN by default\n",
    "            - `method='ffill'`\n",
    "                - forward fill, fills missing values with last non-null value\n",
    "            - `method='bfill'`\n",
    "                - backward fill, fills from next value backwards\n",
    "\n",
    "#### Changing Column Labels\n",
    "- `df.columns = list_of_labels`\n",
    "    - the `list_of_labels` must include the correct number of labels\n",
    "\n",
    "#### Convert Dataframe to Numpy Array\n",
    "- `array = dataframe.values`\n",
    "    - these \"values\" must all be the same type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Elements in a Dataframe\n",
    "#### Select rows or columns, dataframe as `df`\n",
    "- Selecting values\n",
    "    - use the `.values` attribute to return the values as a numpy array\n",
    "    - can use this on a single column or selection\n",
    "        - `df_series_obj = df['column_name']`\n",
    "        - `np_array = df.series_obj.values`\n",
    "        - or simply `np_array = df['column_name'].values`\n",
    "- Select your index values\n",
    "    - `idx_vals = df.index.values`\n",
    "        - returns a list of the index values for each row\n",
    "- Select entire column(s) using col names\n",
    "    - `df['column_name']`\n",
    "        - returns a pandas series object, with extra info in it (not a dataframe)\n",
    "    - `df[['column_name']]`\n",
    "        - returns a dataframe object\n",
    "        - can supply multiple column names in the supplied list\n",
    "- Selecting row(s) with slicing\n",
    "    - `df[start:end:stride]`\n",
    "        - specify the index for *start* and *end*\n",
    "        - works like slicing a list\n",
    "        - returns the *start* index and stops at index before the *end* index\n",
    "        - leave *start* empty to start at the beginning\n",
    "        - leave *end* empty to slice until the end\n",
    "        - *stride* is the frequency of elements to choose (blank=1)\n",
    "- Selecting time series indexed rows with slicing\n",
    "    - `df['datetime']` or `df.loc['datetime']`\n",
    "        - supply the datetime as a string\n",
    "        - if date and time info, can supply a date, to select all rows/times from that date\n",
    "            - can supply just the year, year-month, year-month-day\n",
    "                - will select everything that applies\n",
    "    - `df['datetime_start':'datetime_end']` or `df.loc['start':'end']`\n",
    "        - selects everything in the range, including the 'stop' datetime\n",
    "- loc\n",
    "    - `df.loc['row_label']`\n",
    "        - returns a pandas series object\n",
    "        - values are returned as a list\n",
    "    - `df.loc[['row_label']]`\n",
    "        - returns a pandas dataframe object\n",
    "        - can include multiple row labels in the list\n",
    "    - `df.loc[['row_label'], ['column_label']]`\n",
    "        - can supply a second list containing column labels to select\n",
    "    - `df.loc[:, ['column_label']]`\n",
    "        - selects all rows and the columns you specify in the second list\n",
    "- iloc\n",
    "    - Syntax for `row`, `column`, and `stride`\n",
    "        - `row` & `column`\n",
    "            - supply an int to access a single row/column\n",
    "            - supply a list within `[]` to access multiple rows/columns\n",
    "            - using `:`\n",
    "                - `[start:stop]`\n",
    "                - `[:3]` start at the beginning and include 3 rows/columns (not inclusive of index 3)\n",
    "                - `[3:]` start at index 3 and include the rest of the values\n",
    "    - same as loc, except you supply indexes rather than names\n",
    "        - `df.iloc[row, column, stride]`\n",
    "        - supply `row`, `column`, `stride` values within `[]` as a list to return a dataframe\n",
    "    - can join with boolean indexing\n",
    "        - `df.iloc[:, [True, False, True, False]]`\n",
    "            - returns the columns at indexes 0 and 2\n",
    "            - list of booleans must match the number of columns\n",
    "    - **Lambda Functions**\n",
    "        - `df.iloc[lambda x: x.index % 2 == 0]`\n",
    "            - selects only even rows\n",
    "        - `df.iloc[:, lambda df: [0, 2]]`\n",
    "            - selects all rows and columns at indexes 0 and 2\n",
    "    - Examples:\n",
    "        - `df.iloc[1, 2]`\n",
    "            - select value in second row, third column\n",
    "        - `df.iloc[[1]]`\n",
    "            - select the 2nd row as a dataframe\n",
    "        - `df.iloc[[0, 1, 2], [0, 2]]`\n",
    "            - select the first 3 rows and the first/third column as dataframe\n",
    "        - `df.iloc[:, [4, 5]]`\n",
    "            - all rows in the 5th/6th columns\n",
    "        - `df.iloc[1:3, 0:3]`\n",
    "            - rows 1 and 2, columns 0, 1, and 2\n",
    "            \n",
    "#### Dropping Columns\n",
    "- You can drop entire columns\n",
    "    - store the result in a new df\n",
    "- `df_dropped = df.drop(drop_col_list, axis='columns')`\n",
    "    - easy way to subset data if only wanting certain columns\n",
    "\n",
    "#### Boolean Indexing\n",
    "- Combine conditionals with indexing\n",
    "- See above for **combining with iloc**\n",
    "- Return a series object full of booleans\n",
    "    - `df['column_name']conditional`   # conditional something like `< value`\n",
    "        - can supply whatever conditional you choose\n",
    "- Can use the series object as the index to return a dataframe that only selects 'True' values\n",
    "    - Use directly as the index\n",
    "        - `df[df['column_name'] < value]`\n",
    "    - Store in a variable first\n",
    "        - `bool_index = df['column_name'] = value`  # returns a series object\n",
    "        - `df_new = df[bool_index]` # returns a dataframe\n",
    "- Logical operators\n",
    "    - Use numpy logical and/logical or\n",
    "    - `bool_index = np.logical_and(df['column_name'] > 8, df['column_name'] < 20)`  # returns a series object\n",
    "    - `df_new = df[bool_index]`  # returns a dataframe\n",
    "    - Use `np.logical_or` the same way\n",
    "    \n",
    "#### Assigning New Dataframe Using Boolean Indexing on Data\n",
    "- `filter = df['col'] == value`\n",
    "    - 'value' can be a string used to divide the dataframe (like 'SC' or 'setosa')\n",
    "- `df_filtered = df.loc[filter, :]`\n",
    "    - extracts the filtered data into a new dataframe\n",
    "- All at once\n",
    "    - `df_filtered = df[df['col'] == value]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Colors   Spanish  Length_Colors  Length_Spanish\n",
      "0   Brown      Cafe              5               4\n",
      "1   Green     Verde              5               5\n",
      "2   Black     Negro              5               5\n",
      "3  Yellow  Amarillo              6               8\n",
      "\n",
      "   Colors   Spanish  Length_Colors  Length_Spanish\n",
      "0   Brown      Cafe              5               4\n",
      "1   Green     Verde              5               5\n",
      "2   Black     Negro              5               5\n",
      "3  Yellow  Amarillo              6               8\n",
      "\n",
      "   Colors   Spanish  Length_Colors  Length_Spanish\n",
      "0   Brown      Cafe              5               4\n",
      "3  Yellow  Amarillo              6               8\n",
      "\n",
      "   Length_Colors  Length_Spanish\n",
      "1              5               5\n",
      "2              5               5\n",
      "3              6               8\n",
      "\n",
      "   Colors   Spanish\n",
      "2   Black     Negro\n",
      "3  Yellow  Amarillo\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe from a dictionary\n",
    "colors = ['Brown', 'Green', 'Black', 'Yellow']\n",
    "spanish = ['Cafe', 'Verde', 'Negro', 'Amarillo']\n",
    "length_colors = [5, 5, 5, 6]\n",
    "length_spanish = [4, 5, 5, 8]\n",
    "dict1 = {'Colors': colors, 'Spanish': spanish, 'Length_Colors': length_colors, 'Length_Spanish': length_spanish}\n",
    "df = pd.DataFrame(dict1)\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# alt syntax to stitch a dataframe from lists\n",
    "# using same lists above\n",
    "# this method is more scalable\n",
    "labels = ['Colors', 'Spanish', 'Length_Colors', 'Length_Spanish']\n",
    "cols = [colors, spanish, length_colors, length_spanish] # list of lists\n",
    "zipped = list(zip(labels, cols))\n",
    "dict2 = dict(zipped)\n",
    "df2 = pd.DataFrame(dict2)\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "# select all columns and rows that have spanish != 5\n",
    "bool_index = df['Length_Spanish'] != 5\n",
    "print(df[bool_index])\n",
    "print()\n",
    "\n",
    "# select both length cols where Length_Colors is 5 or more and Length_Spanish is 5 or more\n",
    "bool_index = np.logical_and(df['Length_Colors'] >= 5, df['Length_Spanish'] >= 5)\n",
    "df_subset = df[bool_index]\n",
    "print(df_subset.loc[:, ['Length_Colors', 'Length_Spanish']])\n",
    "print()\n",
    "\n",
    "# select the last two rows and first two cols\n",
    "print(df.iloc[2:,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with String Data\n",
    "- Can chain `.str` methods to work with string data\n",
    "- `df['str_col'].str.upper()`\n",
    "    - returns a series (does not modify the data in place) with all caps\n",
    "- `df['str_col'].str.contains(substring)`\n",
    "    - returns a series of True/False values based on whether each entry contains the supplied substring\n",
    "    - chain `.sum()` to the end of this, to get a count of the number of occurrences\n",
    "        - since True = 1\n",
    "- `df['str_col'] = df['str_col'].str.strip()`\n",
    "    - strip whitespace from strings\n",
    "    - works on column names, just use `df.columns`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Numbers\n",
    "- May need to clean some data\n",
    "    - `df['column'] = pd.to_numeric(df['column'], errors='coerce')`\n",
    "        - `errors='coerce'` will force the conversion adding NaN for non-numerics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Datetimes\n",
    "- `pd.to_datetime(list, format='')`\n",
    "    - convert a list of values to datetimes\n",
    "    - can supply a format string (using standard format chars like %Y-%m ...)\n",
    "    - may need to convert the data to string format first and format properly\n",
    "        - `df['date'] = df['date'].astype(str)`\n",
    "        - `df['time'] = df['time'].apply(lambda x: '{:0>4}'.format(x))`\n",
    "            - pad leading zeros on time if necessary\n",
    "        - `dt_string = df['date'] + df['time']`\n",
    "        - `date_times = pd.to_datetime(dt_string, '%Y/%m/%d%H%M')`\n",
    "        - `df_clean = df.set_index(date_times)`\n",
    "- `df['date_col'].dt.hour`\n",
    "    - can use datetime attributes to access pieces of a datetime from each value\n",
    "        - this example will return a series containing only the hour for each datetime\n",
    "- Convert Timezones\n",
    "    - make datetimes 'aware' by setting a local timezone\n",
    "        - `aware_dates = df['date_col'].dt.tz_localize(timezone_string)`\n",
    "            - where `timezone_string` is in the proper format ('US/Central')\n",
    "    - convert datetiems\n",
    "        - `eastern_dates = aware_dates.dt.tz_convert('US/Eastern')`\n",
    "    - can chain the entire thing together (must repeat the `.dt.` part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "- Often used with datetimes for summary info\n",
    "    - mean, count, sum, etc.\n",
    "- `df.resample(freq)` usually chained with a stat method call\n",
    "    - `freq` is a string to specify the frequency you want\n",
    "        - 'min' or 'T' for minute\n",
    "        - 'H' for hourly\n",
    "        - 'D' for daily\n",
    "        - 'B' for business day\n",
    "        - 'W' for weekly\n",
    "        - 'M' for monthly\n",
    "        - 'Q' for quarterly\n",
    "        - 'A' for annually\n",
    "    - can add an integer to specify every 2 or 3 days etc.\n",
    "        - `df.loc[:,'col'].resample('2W').mean()`\n",
    "    - should chain summary functions to the resample call\n",
    "        - `df['col'].resample('D').mean()`\n",
    "- Chaining multiple methods is possible\n",
    "    - `df.resample('M').sum().max()`\n",
    "        - returns the maximum monthly sum\n",
    "- Downsampling\n",
    "    - reducing datetime rows to a slower frequency (yearly to monthly)\n",
    "    - no additional methods need to be chained beyond those desired\n",
    "- Upsampling\n",
    "    - increasing the frequency (weekly to daily)\n",
    "    - need to tell pandas how to fill the extra data\n",
    "    - `df.loc['yyyy-dd-mm':'yyyy-dd-mm', 'col'].resample('4H').ffill()`\n",
    "        - will make the time appear every 4 hours, (even if all you had was daily)\n",
    "        - will forward fill using values from previous times until a new value is encountered\n",
    "            - good for running totals\n",
    "        - `fill_method` options\n",
    "            - `ffill` forward fill\n",
    "            - `bfill` backward fill\n",
    "            - `pad` in between forward and backward\n",
    "            - `first` only keeps the actual values, and fills with NaN values\n",
    "    - interpolating data rather than filling\n",
    "        - `df.resample('A').first().interpolate(how='linear')`\n",
    "            - will use a linear interpolation to make a coarse time series yearly\n",
    "        - use `first` as the fill method for upsampling\n",
    "        - use `.interpolate(how=type)` to specify how to fill\n",
    "            - where `type` is a string specifying how to fill\n",
    "- Rolling Mean\n",
    "    - `data.rolling(window=).mean()`\n",
    "        - calculates a smooth 'rolling' mean for you data or data slice\n",
    "        - `window=24` will compute new values for each hourly point\n",
    "            - based on a 24 hour window stretching out behind each point\n",
    "        - `window=7` after a daily resample will do it daily\n",
    "            - still trying to figure out how the `window` arg works\n",
    "            - `data.resample('D').max().rolling(window=7).mean()`\n",
    "                - calculates the rolling mean over 7 days of the daily maximum (I think)\n",
    "                - so you still get a daily max, but not until day 7\n",
    "                    - means are smoothed by using 7 daily maxes prior to each day in the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "- Works like numpy broadcasting\n",
    "- Syntax:\n",
    "    - `df['column_name'] = value`\n",
    "        - every row in 'column_name' has value of 'value' now\n",
    "        - this 'column_name' can be a new or existing column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping Through Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Column Labels\n",
    "    - `for i in df: statements`\n",
    "- Rows  # need to use `.iterrows()` method\n",
    "    - `for index, row in df.iterrows(): statements`\n",
    "        - `index` refers to the row labels\n",
    "        - `row` refers to a series object including col name and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colors\n",
      "Spanish\n",
      "Length_Colors\n",
      "Length_Spanish\n"
     ]
    }
   ],
   "source": [
    "# using the df created above\n",
    "# note that there is no col label for the row labels\n",
    "\n",
    "for i in df:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 0     Spanish: Cafe        Spanish Length: 4\n",
      "Row: 1     Spanish: Verde       Spanish Length: 5\n",
      "Row: 2     Spanish: Negro       Spanish Length: 5\n",
      "Row: 3     Spanish: Amarillo    Spanish Length: 8\n"
     ]
    }
   ],
   "source": [
    "# access columns\n",
    "# .ljust(width) helps with alignment and spacing\n",
    "for index, row in df.iterrows():\n",
    "    print(('Row: ' + str(index)).ljust(10), ('Spanish: ' + str(row[1])).ljust(20), 'Spanish Length: ' + str(row[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "15\n",
      "15\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# loop through a column's values\n",
    "for index, row in df.iterrows():\n",
    "    print(row[3] + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a New Column Based on a Calculation\n",
    "- Using `.iterrows()` can do the same thing, but it's less efficient and best on small dataframes\n",
    "- `df['new_column'] = df['column'].apply(function)`\n",
    "    - supply a new column name and a function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     brown\n",
      "1     green\n",
      "2     black\n",
      "3    yellow\n",
      "Name: color_lower, dtype: object\n",
      "\n",
      "0    15\n",
      "1    15\n",
      "2    15\n",
      "3    16\n",
      "Name: length_plus_ten, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a new column from the calculation above\n",
    "df['color_lower'] = df['Colors'].apply(str.lower)\n",
    "print(df['color_lower'])\n",
    "print()\n",
    "\n",
    "# apply a numeric function to a column to create a new column\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "\n",
    "df['length_plus_ten'] = df['Length_Colors'].apply(add_ten)\n",
    "print(df['length_plus_ten'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With File Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving a DataFrame into a File\n",
    "- `df.to_csv(filename[, sep])`\n",
    "    - where `filename` is a string of your filename\n",
    "    - `sep` can set a delimiter to other than comma (default)\n",
    "        - `sep='\\t'` for tab separated (use '.tsv' rather than '.csv' in file name)\n",
    "- `df.to_excel(filename)`\n",
    "    - name `filename` with '.xlsx' extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Flat Files\n",
    "- Such as csv and txt files with rows and cols\n",
    "- `dataframe = pd.read_csv(filename[, sep][, comment][, na_values][, nrows][, header][, names][, parse_dates)`\n",
    "    - `index_col='col'`\n",
    "        - can also supply a column name to use as the index\n",
    "        - useful when parsing dates (see below)\n",
    "    - `sep` is pandas version of delimiter with default `','`\n",
    "    - `comment` takes the char that comments appear after (for python it's '#')\n",
    "    - `na_values` \n",
    "        - takes a list of strings to identify/replace with NaN\n",
    "            - blank spaces preceding values in the data can affect this\n",
    "            - so check for them if experiencing issues\n",
    "        - can accept a dictionary using column names as indexes and lists of values to replace for the value\n",
    "            - `na_values={'col1':['  -1', ' -1', '-1'], 'col2':['no_data', 'N/A']}`\n",
    "    - `nrows` specifies an integer for the number of rows to retrieve\n",
    "    - `header=None` if no header\n",
    "        - `names=col_names` where 'col_names' is a list of header names for each column\n",
    "        - the supplied list should have the same length as the number of columns\n",
    "    - `parse_dates=[[index1, index2, index3]]`\n",
    "        - can also set `parse_dates=True` and see what happens\n",
    "            - combine with `index_col='date'` to index by these dates\n",
    "        - intelligently parses the date entries from each supplied index and combines them into one datetime\n",
    "        - use integers for the indexes (i.e. `parse_dates=[[4, 5]]`) to specify output of parsing\n",
    "        - use a column name for the indexes (i.e. `parse_dates=[['year', 'month']]`)\n",
    "            - use a single column name to keep the datetime together `parse_dates=['date']`\n",
    "        - it may even parse the column name, need to test\n",
    "    - view the header and first 5 lines of the dataframe with `.head()` method `dataframe.head()`\n",
    "    \n",
    "    - **Parse the date and set as index during import**\n",
    "        - set `index_col='date'` and `parse_dates=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating Through Large Files\n",
    "- Simple example using chunking to record each unique value and it's number of occurrences\n",
    "    - Initialize empty dictionary\n",
    "        - `dict1 = {}`\n",
    "    - Iterate over the file\n",
    "          `for chunk in pd.read_csv(filevariable, chunksize=100):`\n",
    "              `# iterate over a column in the file`\n",
    "              `for entry in chunk['col_name']:`\n",
    "                  `if entry in dict1.keys():`\n",
    "                      `dict1[entry] += 1`\n",
    "                  `else:`\n",
    "                      `dict1[entry] = 1`\n",
    "    - Convert to a dataframe\n",
    "        - `df = pd.DataFrame(dict1)`\n",
    "\n",
    "\n",
    "#### Complex Example\n",
    "- Use a reader object to read the files a specific number of lines at a time\n",
    "    - `file_name_reader = pd.read_csv('filename', chunksize=num)`\n",
    "        - common to store filename in a variable and use the variable\n",
    "        - *num* is the number of lines to read, 1000 is a good number\n",
    "- Initialize empty df\n",
    "    - `data = pd.DataFrame()`\n",
    "- Iterate over each chunk\n",
    "    - `for grp in file_name_reader:` \n",
    "          `filtered_data = grp[grp['col_of_interest'] == condition]`\n",
    "          # exclude all data not meeting condition\n",
    "- Zip any columns you want\n",
    "    - `data_zip = zip(filtered_data['col_name1'], filtered_data['col_name2])`\n",
    "- Convert zip object to a list\n",
    "    - `data_list = list(data_zip)`\n",
    "- Create new dataframe column (this example does a calculation on the two columns to get a %)\n",
    "    - use list comprehension if needed to create your new column\n",
    "        - `filtered_data['new_column'] = [int(tup[0] * tup[1] * 0.01) for tup in data_list]`\n",
    "- Append this 'chunk' to the dataframe\n",
    "    - `data = data.append(filtered_data)\n",
    "- Can nest this entire thing in a function to call by supplying relatively few parameters\n",
    "    - DataCamp example similar to this in old `Python Library.docx` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel Files\n",
    "- `datafile = pd.ExcelFile('filename')`\n",
    "- view different sheets in the file/dataframe\n",
    "    - `print(datafile.sheet_names)`\n",
    "    - use `.sheet_names` attribute of this object\n",
    "- extract a sheet into a dataframe\n",
    "    - `dataframe = datafile.parse(sheet[, skiprows][, names][, usecols])`\n",
    "        - `sheet` supply sheet name as a str or index as float (0 indexed)\n",
    "        - the following args must be in list format\n",
    "            - `[arg]` if only supplying one value\n",
    "        - `skiprows` supply a list of rows to skip (0 indexed)\n",
    "        - `names` supply a list of names for your imported columns\n",
    "        - `usecols` supply a list of columns to import (0 indexed)\n",
    "- Read Excel file and store each sheet as a dataframe with sheet names as the keys to each individual dataframe\n",
    "    - `df = pd.read_excel('filename', sheetname=none)`\n",
    "        - can specify a 'sheet' or if sheet='none' will save all sheets using sheet names as keys\n",
    "        - can use a 'url' as the 'filename' to scrape data from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAS and Stata Files\n",
    "- SAS Files\n",
    "    - `from sas7bdat import SAS7BDAT`\n",
    "    - `with SAS7BDAT('filename.sas7bdat') as file:`\n",
    "          `dfsas = file.to_data_frame()`\n",
    "- Stata Files\n",
    "    `data = pd.read_stata('filename.dta')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 Files\n",
    "- HDF5 is becoming the industry standard for big data sets\n",
    "- hierachy of key values, where a value here then becomes a key\n",
    "- `import h5py`\n",
    "  `filename = filename.hdf5`\n",
    "  `data = h5py.File(filename, 'r')`\n",
    "- exploring data structure\n",
    "    - `for key in data.keys():`\n",
    "      `print(key)`\n",
    "    - provides keys that can be accessed such as 'meta' for metadata\n",
    "    - access its contents\n",
    "        - `for key in data['meta'].keys():`\n",
    "          `print(key)` returns another key in this example 'Description'\n",
    "    - accessing values\n",
    "        - `data['meta']['Description'].value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping Data fro the Web\n",
    "- Some functionality using the 'urllib' package\n",
    "    - `from urllib.request import urlretrieve, urlopen, Request`\n",
    "    - import not necessary when using some of the functions below\n",
    "- Import data into a dataframe using a url\n",
    "    - `url = 'http://....filename.csv'`\n",
    "    - `df = pd.read_csv(url, sep=';')` using the appropriate separator (delimiter)\n",
    "    - `df = pd.read_excel(url, sheetname=none)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Databases\n",
    "- Need to import the appropriate package\n",
    "    - `from sqlalchemy import create_engine`\n",
    "- Creating an engine (sqlalchemy package)\n",
    "    - `engine = create_engine('sqlite:///db_name.sqlite')`\n",
    "        - above syntax `'db_type:///db_name.extension'`\n",
    "- Running a query using Pandas\n",
    "    - `df = pd.read_sql_query(\"SELECT * FROM table_name\", engine)\n",
    "    - `engine` is the engine to connect to (see above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Concatenating Data into a Dataframe from Many Files\n",
    "#### Concatenating Dataframes Using Pandas\n",
    "- Useful when combining data sources\n",
    "- `df_concat = pd.concat([df1, df2], axis=0,ignore_index=True)`\n",
    "    - works well when your dataframes have the same columns in the same order\n",
    "        - adds rows, keeping your columns\n",
    "    - `axis` is optional\n",
    "        - `axis=0` is default, and adds rows to your columns\n",
    "        - `axis=1` will add new columns on the right of the dataframe, matching on row index\n",
    "    - `ignore_index` is optional\n",
    "        - default is `ignore_index=False` and keeps original index values (produces duplicate row indexes)\n",
    "        - `ignore_index=True` will reindex the new dataframe\n",
    "- Use `glob` to find files based on a pattern\n",
    "    - need to `import glob`\n",
    "    - useful when trying to process thousands of files for concatenation\n",
    "    - uses **wildcards** to help matching\n",
    "        - `*` matches zero or more of any char\n",
    "        - `?` matches any single char in that position\n",
    "        - `[ ]` matches chars specified within\n",
    "            - `[0-9]` matches number 0-9\n",
    "            - `[09]` mathces 0 and matches 9\n",
    "    - creates a list of file names that match your pattern\n",
    "    - Example:\n",
    "        - `csv_files = glob.glob('*.csv')` will store a list of all csv files\n",
    "- Example: to combine these skills to create a large dataframe from many files\n",
    "    - `list_data = []`\n",
    "    - `for filename in csv_files:`\n",
    "        - `data = pd.read_csv(filename)`\n",
    "        - `list_data.append(data)`\n",
    "            - this results in a list of dataframes, which can be loaded into `pd.concat`\n",
    "    - `df = pd.concat(list_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
